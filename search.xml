<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java集合框架之LinkedHashMap详解]]></title>
    <url>%2F2017%2F09%2F05%2Fjava%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E4%B9%8BLinkedHashMap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[本文基于jdk1.8介绍LinkedHashMap。 LinkedHashMap在上一篇文章Java集合框架之HashMap详解中， 我们介绍了Java集合框架的一个类HashMap。通过源码分析，我们了解了HashMap的存储结构和内部实现，如果还有不清楚的,那就再回顾一下，因为我们今天要介绍的LinkedHashMap是HashMap的子类，很多方法和属性都直接继承于HashMap。 Map接口类图 与HashMap异同从上面的类图中我们可以看到,LinkedHashMap直接继承自HashMap，所以LinkedHashMap拥有HashMap的大部分特性，最多只允许一个key为null，可以有多个value为null。一些主要的方法和属性也直接继承自HashMap，并对其中某些方法进行了重写。LinkedHashMap与HashMap最大的不同在于LinkedHashMap保持了元素的有序性，即遍历LinkedHashMap的时候，得到的元素的顺序与添加元素的顺序是相同的，可以按照插入序 (insertion-order)或访问序 (access-order)来对哈希表中的元素进行遍历。 所谓插入顺序，就是 Entry被添加到 Map 中的顺序，更新一个 Key 关联的 Value 并不会对插入顺序造成影响,而访问顺序则是对所有 Entry 按照最近访问(least-recently)到最远访问(most-recently)进行排序，读写都会影响到访问顺序，但是对迭代器 (entrySet(), keySet(), values()) 的访问不会影响到访问顺序。默认是按插入顺序排序，如果指定按访问顺序排序，那么调用get方法后，会将这次访问的元素移至链表尾部，不断访问可以形成按访问顺序排序的链表。 顺序存取原理LinkedHashMap之所以能实现存取的顺序性，主要是他重新定义了 Entry&lt;K,V&gt; ，这个新的 Entry&lt;K,V&gt; 继承自HashMap.Node&lt;K,V&gt;，并做了新的扩展，下面我们结合源码来分析一下。 123456static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 存取结构由上面的代码我们可以看出，这个自定义的 Entry&lt;K,V&gt;比 HashMap.Node&lt;K,V&gt;多了两个属性，before和after。正是使用这两个关键的属性，在LinkedHashMap内部实现了一个双向链表。数据结构的知识大家再回忆一下（想不起来的可以去面壁了），双向链表就是每个节点除了存储数据本身之外，还保存着两个指针，在java里面就是指向对象的引用，一个是前驱节点，也就是他的前一个节点的引用，一个是后继节点，也就是他的后一个节点的引用。这样，就可以实现存储一个有序节点的数据结构了。（这里说明下，在jdk1.7中，使用的结构为环形双向链表）另外，继承自HashMap.Node&lt;K,V&gt;的Entry&lt;K,V&gt;自身还保留着用于维持单链表的next属性，因此LinkedHashMap的Entry节点具有三个指针域，next指针维护Hash桶中冲突key的链表，before和after维护双向链表。结构如下图所示： LinkedHashMap存储结构以上就是LinkedHashMap的数据结构，但是光有数据机构显然无法完成有序的存取，下面我们继续来看一下，LinkedHashMap的存取过程。 存取过程上面提到LinkedHashMap继承自HashMap，所以，LinkedHashMap的自身便拥有了HashMap全部的属性和方法。由代码我们也能看出，LinkedHashMap自身并没有实现put方法，而是直接使用其父类HashMap的put方法。不同的是，在创建Entry时，重写了父类的newNode(int hash, K key, V value, Node&lt;K,V&gt; e) {}方法，并实现了父类预留的回调方法，通过重写父类的方法和回调方法，LinkedHashMap扩展了HashMap，使其拥有了保持存取顺序性的能力。从这点我们也可以看出，java的开发团队将这一功能实现的比较优雅，其中的思想值得我们在开发中借鉴和学习，这也是我们阅读java源码的意义所在。1234567891011121314151617181920//创建新的节点 Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p; &#125; // link at the end of list //将节点添加到双向链表尾部 private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; &#125; LinkedHashMap的put过程和HashMap大致相同，包括计算hash值、计算table数组索引、判断数组是否为空等步骤，不同的是创建节点的过程。从上面的代码中我们可以看出，重写的这个newNode方法代码比较简洁，首先实例化一个双链表结构的Entry&lt;K,V&gt; p，这里会首先调用其父类 HashMap.Node的构造方法，维护着一个单链表的结构。实例化结束后，会调用一个linkNodeLast的私有方法，这个方法完成了将新的元素添加至双向链表的尾部的功能。我们知道，在HashMap中，如果单链表超过一定的长度，就会被转换为红黑树，那么在LinkedHashMap中也是同样的逻辑，于是就有了下面的代码。 1234567891011121314//创建新的红黑树节点TreeNode&lt;K,V&gt; newTreeNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(hash, key, value, next); linkNodeLast(p); return p; &#125; //将链表节点转换为红黑树节点 TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; LinkedHashMap.Entry&lt;K,V&gt; q = (LinkedHashMap.Entry&lt;K,V&gt;)p; TreeNode&lt;K,V&gt; t = new TreeNode&lt;K,V&gt;(q.hash, q.key, q.value, next); transferLinks(q, t);//将双向链表中的TreeNode替换为新的普通节点 return t; &#125; 这两个也是被重写的方法，当存储结构为红黑树的时候，调用newTreeNode方法创建红黑树节点。当需要将链表转换为红黑树结构时，调用replacementTreeNode方法将双向链表中的TreeNode替换为新的链表节点。由以上分析过程可以得出结论，在 LinkedHashMap 中，所有的 Entry 都被串联在一个双向链表中。每次在新建一个节点时都会将新建的节点链接到双向链表的末尾。这样从双向链表的尾部向头部遍历就可以保证插入顺序了，头部节点是最早添加的节点，而尾部节点则是最近添加的节点。上面我们还提到，LinkedHashMap可以实现插入的顺序和访问的顺序，那么访问的顺序是怎样实现的呢？下面我们来看一下。123456//构造方法public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; putMapEntries(m, false);&#125; 我们通过观察LinkedHashMap的构造函数可以发现有这样一个字段，accessOrder，他的初始值为false。这个字段的意思是是否使用访问序,所以LinkedHashMap的默认顺序为插入顺序。上文我们提到了在HashMap类中预留了几个回调方法，这几个方法在HashMap中并没有实现，而在LinkedHashMap中这几个方法都有了具体的实现,这些方法就是为了实现访问序，下面我们结合代码来看一下。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 //移除节点的回调方法 void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink //移除一个节点，双向链表中的连接关系需要调整 LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b; &#125;//插入节点的回调方法//构造方法中调用 putMapEntries调用时 evict为false void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; //first是头元素，也是最老的元素 //在插入序中，就是最先插入的元素 //在访问序中，就是最远被访问的元素 //这里removeEldestEntry(first)始终返回true，即不删除最老的元素 //如果是一个容量固定的cache，可调整removeEldestEntry(first)的实现 if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125; &#125; //访问元素之后的回调方法 void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; //如果是访问序，且当前节点并不是尾节点 //将该节点置为双向链表的尾部 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125; &#125; 在插入节点、删除节点和访问节点后会调用相应的回调函数。可以看到，在 afterNodeAccess 方法中，如果该LinkedHashMap是访问序，且当前访问的节点不是尾部节点，则该节点会被置为双链表的尾节点。即，在访问序下，最近访问的节点会是尾节点，头节点则是最远访问的节点。 遍历123456789101112131415161718192021222324252627282930313233343536373839404142 //所有的节点都被串联在双向链表中，迭代器在迭代时可以利用双向链表的链接关系进行//双向链表的顺序是按照插入序或访问序排列的// Iteratorsabstract class LinkedHashIterator &#123; LinkedHashMap.Entry&lt;K,V&gt; next; LinkedHashMap.Entry&lt;K,V&gt; current; int expectedModCount; LinkedHashIterator() &#123; next = head; expectedModCount = modCount; current = null; &#125; public final boolean hasNext() &#123; return next != null; &#125; final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123; LinkedHashMap.Entry&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); current = e; next = e.after;//直接访问after引用 return e; &#125; public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount; &#125;&#125; 可以看到，在遍历所有节点时是通过节点的 after 引用进行的。这样，可以从双链表的头部遍历到到双链表的尾部。 总结关于LinkedHashMap，我们就介绍到这里，当然，在这里只列出了部门比较重要的方法，还有很多的方法我们没有分析。如果有兴趣，大家可以对照着jdk1.7和jdk1.8的源码进行分析，会发现两者的实现方式还是有很大区别的。 参考http://blog.jrwang.me/2016/java-collections-linkedhashmap/http://www.cnblogs.com/chenpi/p/5294077.htmlhttp://blog.csdn.net/qq_24692041/article/details/64904806]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>集合</tag>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架之HashMap详解]]></title>
    <url>%2F2017%2F08%2F31%2Fjava%2FHashMap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[基础扫盲本文基于jdk1.8介绍HashMap。 java 集合框架 Java的集合类主要由两个接口派生而出：Collection和Map，Collection和Map是Java集合框架的根接口，这两个接口又包含了一些接口或实现类。Set和List接口是Collection接口派生的两个子接口，Queue是Java提供的队列实现，类似于List。Map是一个映射接口，其中的每个元素都是一个key-value键值对，抽象类AbstractMap通过适配器模式实现了Map接口中的大部分函数，TreeMap、HashMap、WeakHashMap等实现类都通过继承AbstractMap来实现，另外，不常用的HashTable直接实现了Map接口。对于Set、List和Map三种集合，最常用的实现类分别是HashSet、ArrayList和HashMap三个实现类。 Map接口类图 (1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。(2) Hashtable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。(3) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。(4) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 Hash 知识 维基百科的定义 散列（英语：Hashing）是电脑科学中一种对资料的处理方法，通过某种特定的函数/算法（称为散列函数/算法）将要检索的项与用来检索的索引（称为散列，或者散列值）关联起来，生成一种便于搜索的数据结构（称为散列表）。也译为散列。旧译哈希（误以为是人名而采用了音译）。它也常用作一种资讯安全的实作方法，由一串资料中经过散列算法（Hashing algorithms）计算出来的资料指纹（data fingerprint），经常用来识别档案与资料是否有被窜改，以保证档案与资料确实是由原创者所提供。 Hash 函数 散列函数（或散列算法，又称哈希函数，英语：Hash Function）是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混合，重新创建一个叫做散列值（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常用一个短的随机字母和数字组成的字符串来代表。好的散列函数在输入域中很少出现散列冲突。在散列表和数据处理中，不抑制冲突来区别数据，会使得数据库记录更难找到。 上面是维基百科给出的定义，通俗点来讲，一般情况下，需要在关键字与它在表中的存储位置之间建立一个函数关系，以f(key)作为关键字为key的记录在表中的位置，通常称这个函数f(key)为哈希函数。 哈希表和查找 哈希表是哈希函数的一个主要应用，使用哈希表能够快速的按照关键字查找数据记录。（注意：关键字不是像在加密中所使用的那样是秘密的，但它们都是用来“解锁”或者访问数据的。）例如，在英语字典中的关键字是英文单词，和它们相关的记录包含这些单词的定义。在这种情况下，哈希函数必须把按照字母顺序排列的字符串映射到为哈希表的内部数组所创建的索引上。哈希表是一个在时间和空间上做出权衡的经典例子,在没有碰撞的情况下，检索时间复杂度为O(1)。 Hash 冲突 对不同的关键字可能得到同一散列地址，即 k1!=k2，而f(k1)==f(k2)，这种现象称为冲突（英语：Collision）。具有相同函数值的关键字对该散列函数来说称做同义词。综上所述，根据散列函数f(k)和处理冲突的方法将一组关键字映射到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为散列表，这一映射过程称为散列造表或散列，所得的存储位置称散列地址。解决碰撞有很多方法可以使用，最常用的包括链地址法和开地址法。HashMap就是用的链地址的方法解决冲突。 HashMap HashMap是我们经常使用一个映射容器，通过牺牲存储空间来换取检索时间，HashMap是采用了hash表数据结构思想来实现。在key未发生冲突的情况下，搜索时间复杂度为O(1),可以快速定位元素。因此在日常开发中也被程序员广泛使用，例如作为关系映射容器、简单缓存、提高检索速度等。HashMap最多只允许一个键值为null(保存在数据列表中的第0个元素的链表上)，允许value为null值。 数据结构 HashMap实现了Map接口，继承AbstractMap。其中Map接口定义了键映射到值的规则，而AbstractMap类提供 Map 接口的骨干实现。java的HashMap结构上采用了数组链表方式，即数组+链表的数据结构，采用这种结构的原因是采用了链地址的方法解决哈希冲突。但是这样带来了一个问题，当某个链表达到一定的长度时，对于链表元素的查找会变成线性搜索，比较耗时。所以在JDK1.8的实现中做了优化，当链表的长度达到一定数量（TREEIFY_THRESHOLD默认值为8）时，会把链表转为红黑树，所以在JDK1.8的版本HashMap的数据结构为数组+链表+红黑树。在HashMap中，通过Node[] table，(jdk 1.7叫做Entry，jdk 1.8加入红黑树后改为Node,原因是和红黑树的实现TreeNode相关联)来实现该结构，该数组可以看做是一个哈希桶数组，每个桶中存放着一个链表，Node是链表节点,并实现了Map.Entry。Node节点存放一个键值对，同时存放一个指向下一个节点的引用。Node是键值对存储单元，通过hash值来确定该元素在数组链表中的位置。基于这个存储结构，我们也可以看出，HashMap是不保证存取的顺序性的，也就是说遍历HashMap的时候，得到的元素的顺序与添加元素的顺序是不同的。123456789101112131415 Node结构源码 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置，hash值不允许修改。 final K key; //key, 都是常数不允许修改。同时key是一个不可变对象。 V value;//对应value Node&lt;K,V&gt; next;//下一个节点 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; 后面代码省略。。。。。。。。。。&#125; 存储结构 存取原理 1.构造函数HashMap提供了四个构造函数：1234HashMap();//构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMap。HashMap(int initialCapacity);//构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMap。HashMap(int initialCapacity, float loadFactor);//构造一个带指定初始容量和加载因子的空 HashMap。HashMap(Map&lt;? extendsK,? extendsV&gt; m); //构造一个映射关系与指定 Map 相同的 HashMap。 在这里出现了两个参数：初始容量，加载因子。这两个参数是影响HashMap性能的重要参数，其中初始容量表示哈希表中桶的数量，也就是上一节提到的Node数组table[]的初始长度，初始容量是创建哈希表时的容量，加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链地址法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。2.几个重要的属性12341. int threshold; // 所能容纳的key-value对极限2. int modCount; // 修改次数3. int size; // 元素数量4. final float loadFactor; // 负载因子 thresholdthreshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。如果容器中的元素数量超过这个值，那么HashMap就会进行扩容，重新调整元素位置。扩容后的容量是之前容量的2倍。在HashMap中容器的长度必须是2的倍数，这种设计主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。 size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。 modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。 TREEIFY_THRESHOLDstatic final int TREEIFY_THRESHOLD = 8;在JDK1.8版本中，对数据结构做了进一步的优化，引入了红黑树。这是一个常数，表示链表长度的一个阈值。如果链表长度大于这个值(默认为8)时，就转为红黑树。利用红黑树提高增删改查的性能，避免之前因为某个链上积累太多元素而影响HashMap性能，使用红黑树使得增删改查等操作复杂度变为O(logN)。3.存取过程put是HashMap的核心方法之一，用于存入数据，下面来分析下put方法的执行流程。 put方法执行顺序根据分析，put方法的执行步骤如下：1.首先判断table是否为null或者length==0,如果是则先做扩容2.计算索引根据键值key计算hash值在数组链表中的索引位置i。如果key为null,则默认保存到0位置的哈希桶，保证了一个hashMap中只有一个值为null的key。判断table[i]是否为空，如果为空则直接插入，执行。否则执行3。3.判断table[i]的首个元素是否和key一样（通过hashCode以及equals判断），如果相同直接覆盖value，否则转向4。4.判断table[i] 是否为treeNode(是否是红黑树)，如果是红黑树，则直接在树中插入键值对，否则转向5。5.遍历table[i]，判断链表中是否存在相同的key,如果存在则直接覆盖。否则在链表尾部插入新节点（JDK1.7是在头部插入）。插入完成后判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作，遍历过程中若发现key已经存在直接覆盖value即可。6.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 具体来看源码：1234567891011121314151617181920212223242526272829303132333435363738394041424344final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0)//1.判断是否table为空 n = (tab = resize()).length;//扩容 if ((p = tab[i = (n - 1) &amp; hash]) == null)//2.根据hash值计算索引，(n - 1) &amp; hash。判断该位置是否为空 tab[i] = newNode(hash, key, value, null);//为空 插入新节点 else &#123;//该位置不为空 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; //3.判断该节点key是否存在 存在直接覆盖value ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //存在直接覆盖value else if (p instanceof TreeNode) //4.判断是否为红黑树 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);//红黑树 直接插入 else &#123; //5.链表操作 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //判断链表该节点是否有子节点 //插入新节点（尾部插入） p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //判断是否存在相同的key 如果存在直接覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //6.如果超过最大容量 扩容 ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 4.HashCode的计算和元素定位HashMap的数据结构决定了在整个使用过程包括增加、删除和查找元素时，定位到哈希桶数组的位置都是很关键的第一步。hashMap采用数组链表结构，我们希望插入的元素在表中尽可能的均匀分布，这样能够提高操作效率。而元素的分布情况与hashCode计算算法有关，直接影响hash离散性能。1234567891011121314// 计算hash值static final int hash(Object key) &#123; //jdk1.8 int h; /** 可以看作两步： 1. h = key.hashCode() 为第一步 取hashCode值 2. h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 **/ return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;// 锁定数组下标位置(锁定hash桶)static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，直接在代码中用(n - 1) &amp; hash替代，实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 定位哈希桶数组分为两个大步骤： 计算hash值(取key的hashCode值、高位运算) 根据hash值定位哈希数组位置在数据结构学习中，计算哈希桶数组位置的常用方式就是取模运算，即index = hash% length。通过这种方式可以使得每个元素能够相对均匀的分布在哈希桶数组中，java中的hash也采用了类似的方式。为了提高计算性能，java采用了&amp;计算代替取模。前面我们提到哈希桶数组的长度是2倍数，这个设置是为了对hashMap中的操作进行优化。比如4的二进制是100， 对4取模操作5%4 = 1相当于 101 &amp; 011 = 001 等于1。在《剑指offer》中“二进制中的1的个数”也巧妙运用了n&amp;(n-1)计算整数中出现1的个数。一个hashCode是32位，而如果哈希桶数组长度比较小时，直接对hashCode进行取模运算只考虑了hashCode的低位字节。Java中同时考虑了高位和低位在计算索引位置的作用，保证高地位Bit都能参与到Hash的计算中。在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，也保证数组table的length比较小的时候，高低Bit都能参与进来，使得元素更加均匀分散。Hash计算方式5.插入元素当元素定位的哈希桶是一个链表时，则采用尾插入法。首先从头遍历链表，根据equals和hashCode来比较key是否相同。因此作为hashMap的key必须同时重载equals方法和hashCode方法。JDK 1.7的链表操作采用了头插入法，即新的元素插入到链表头部。在JDK1.8中采用了尾插入法。插入以后如果链表长度大于8，那么就会将链表转换为红黑树。因为如果链表长度过长会导致元素的增删改查效率低下，呈现线性搜索时间。JDK1.8采用采用红黑树进行优化，进而提高HashMap性能。如果哈希桶是一个红黑树，则直接使用红黑树插入方式直接插入到红黑树中。6.扩容JDK1.8是在插入元素后判断是否进行扩容，而且扩容条件相对于JDK1.7有所变化。JDK1.7是在插入元素前判断是否需要扩容，不仅要求size大于等于threshold，同时需要table[bucketIndex]不为空时才进行扩容。扩容时新的容器容量是原来的两倍。JDK1.8对于扩容过程进行了优化，提高扩容性能。JDK 1.7是通过创建一个容量为原来两倍的新容器，然后遍历原来容器的所有元素并对每个元素重新计算一次在新容器的索引位置，然后插入到新容器中。 参考http://blog.csdn.net/qq_27093465/article/details/52209789http://blog.csdn.net/qq_27093465/article/details/52207152http://www.importnew.com/16599.htmlhttps://tech.meituan.com/java-hashmap.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>集合</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SOA简述]]></title>
    <url>%2F2017%2F08%2F24%2F%E6%9E%B6%E6%9E%84%2FSOA%E7%AE%80%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[混沌接触SOA也有几年时间了，从未对其概念和模式深究。我们总是对自己每天接触的东西习以为常，甚至视而不见。随着互联网的发展，SOA的架构也随之大行其道，随之而来的是各种高大上的架构模型和技术名称，林林总总让人眼花缭乱。一直以来对这些都是模糊的概念，想去深究也屡不出个头绪。最近看了几篇业界大牛的文章，略有感悟，试着整理下思路，理清一些基本的概念和术语。本文侧重以自己的理解描述SOA是什么以及由SOA衍生而来的各种技术名词和他们之间的关系，不会详细阐述SOA的原理和SOA架构的各种实践。 开悟SOA定义 先来一段维基百科对SOA的描述 面向服务的体系结构（英语：service-oriented architecture）是构造分布式计算的应用程序的方法。它将应用程序功能作为服务发送给最终用户或者其他服务。它采用开放标准、与软件资源进行交互并采用表示的标准方式。 怎么样，多么标准的教科书般的定义。不过这个定义未免太过抽象，我们试着从实质的内容来阐述一下，SOA的出现是为了解决一种什么样的问题或者他规定了什么内容。 感性的SOA定义SOA不是一种技术，也不是一个标准，而是一种架构方式，包含了服务提供者、服务调用者、服务管理中心等角色，整个架构模式也是围绕着这些角色如何更有效的互相配合，从而实现SOA架构的商业价值。SOA的应用已经非常普及，毕竟从诞生到现在已经二十余年了。1996年由Gartner公司提出，后经过IBM、SUN、BEA、Oracle等公司完善和推广，SOA的思想和理论逐步得到完善。不管是从概念模型上还是具体应用技术上，都已经得到了全面的发展，也衍生出了很多的新的概念和技术,比如HTTP API,云服务，敏捷开发，持续交付，DevOps等，这些技术的发展和成熟也推动着SOA架构的不断演变。 SOA理念SOA要求开发者从服务集成的角度来设计应用软件，目标为了提高重用性,即使这么做的利益不会马上显现。SOA要求开发者超越应用软件来思考，并考虑复用现有的服务，或者检查如何让服务被重复利用。SOA鼓励使用可替代的技术和方法（例如消息机制），通过把服务联系在一起而非编写新代码来构架应用。 SOA原则服务松耦合(Loosely coupled) - 服务之间的关系最小化，只是互相知道。服务契约 - 服务按照服务描述文档所定义的服务契约行事。服务抽象 - 除了服务契约中所描述的内容，服务将对外部隐藏逻辑。服务的重用性 - 将逻辑分布在不同的服务中，以提高服务的重用性。服务的可组合性 - 一组服务可以协调工作并组合起来形成一个组合服务。服务自治 – 服务对所封装的逻辑具有控制权服务无状态 – 服务将一个活动所需保存的资讯最小化。服务的可被发现性 – 服务需要对外部提供描述资讯，这样可以通过现有的发现机制发现并访问这些服务。 这样，我们对SOA有了一个感性的了解，我们可以这样认为，SOA其实就是利用模块化思维，遵循SOA定义的原则构建分布式应用的架构模式，基于这个理解下面我们再来看一下在SOA架构下的实现方式。 实现Web ServiceWeb Service相信大家对这个名词也不是很陌生吧，不过令人遗憾的是这个现在已经被滥用的太严重了，以至于我们不能清晰的描述出Web Service到底是什么。老规矩，根据维基百科定义Web服务是一种服务导向架构的技术，通过标准的Web协议提供服务，目的是保证不同平台的应用服务可以互操作。 其实，一般情况下可以认为Web service 是SOA架构的一个实例，通常使用HTTP协议，一般使用web服务器作为服务请求的管道。 Web Service要素 SOAP提到Web Service,不得不说到的就是SOAP了。SOAP（原为Simple Object Access Protocol的首字母缩写，即简单对象访问协议）是交换数据的一种协议规范，一个基于XML的可扩展消息信封格式，需同时绑定一个网络传输协议。这个协议通常是HTTP或HTTPS，但也可能是SMTP或XMPP。 WSDLWSDL (Web Service Description Language)也遵循XML格式，用来描述哪个服务器提供什么服务，怎样找到它，以及该服务使用怎样的接口规范，简言之，服务发现。 UUID一个用来发布和搜索WEB服务的协议，应用程序可借由此协议在设计或运行时找到目标WEB服务。 不同厂商的实现不同的厂商根据又发展了自己的协议和实现方式 javaJava API for XML Web Services（JAX-WS）是Java程序设计语言一个用来创建Web服务的API .NET.NET WebService、NET Remoting、WCF Web Service 使用使用Web Service的过程变成，获得该服务的WSDL描述，根据WSDL构造一条格式化的SOAP请求发送给服务器，然后接收一条同样SOAP格式的应答，最后根据先前的WSDL解码数据。绝大多数情况下，请求和应答使用HTTP协议传输，那么发送请求就使用HTTP的POST方法。不过现在为了简化调用过程，又有了新的使用方式，就是舍弃一部分或者完全舍弃SOAP协议，使用HTTP+去掉头尾的SOAP或者HTTP+JSON的方式调实现web service,这种更加轻量的方式又叫做rest方式调用。 Rest 又又又来一个新名词 REST（英文：Representational State Transfer，又称具象状态传输）是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件/程序在网络（例如互联网）中互相传递信息。说到底，REST也只是一种架构风格，而不是协议或标准。但这种新的风格对现有的以SOAP为代表的Web Service造成的冲击也是革命性的，因为它面向资源，甚至连服务也抽象成资源，它和HTTP紧密结合，是无状态的。 传统意义上的rest可能要和soa划在一个层面，都是软件架构的方式，soa是面向服务的软件架构方式，Rest是面向资源的软件架构方式，不过事实上，一些Web Service提供者提供的REST API只有REST的外壳，传输的请求和应答全然是简化了的SOAP，这种新瓶装旧酒的做法只是加深了标准的分歧而已。归根结底REST无法简单地解决一些问题，因此我们只能看到SOAP在REST外壳下的借尸还魂。所以目前rest还是划分到webservice下的一个使用方式的分支，用以区分以soap为协议的传统webservice的调用方法。 通信分布式异构系统的通信上面说到了SOA是构建模块化的分布式系统的架构模式，既然提到了分布式，那不得不说的就是基于分布式的模式下各个系统或者模块间的通信了。SOA建立在分布式和异构平台下，分布式程序的基础是RPC调用，RPC的本质是网络传输和对象序列化，需要用RPC在分布式和异构系统中进行通信。当然这只一种选择，还可以选择比如基于message的方式进行通讯和集成，这里就不展开说明了。 RPC 维基百科对于RPC的定义远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。 RPC目标RPC的主要目标是让构建分布式计算（应用）更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。 为实现该目标，RPC框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。 RPC性能不过RPC是跨进程进行调用，如果在进程内进行方法调用，所需的时间量级是 ns（纳秒）级，而进程间的RPC方法调用时间量级通常是 ms（毫秒）级，它们之间有着10的六次方的效率之差，所以选择这只方式进行通讯意味着要要牺牲一定的性能，而且一般在这种架构下完成一个功能或者一个接口可能需要多次的RPC调用，这就要求我们在实现接口是特别注意性能问题，一点点的性能差异在这种架构下都会被放大。 分布式服务框架业界主流框架上面提到针对SOA的实现，各大厂商都提供了自己的技术实现和一整套的解决方案，但是在大规模异构的分布式系统中，还是希望能有一个比较统一的框架来实现各种异构系统的通信和集成，这个时候，就有了各种RPC框架，或者叫服务框架。一般分为两种，一种是比较狭义的RPC框架，属于轻量级框架，仅具备完整的RPC调用功能（比如像thrift、gRPC等），在各种复杂的架构和业务场景下，这种框架显得有些捉襟见肘，不具备比如调用监控、服务路由等功能。这时候，又衍生出了另外一种框架，分布式服务框架，包括RPC调用、服务治理、注册发现、流量切换、服务路由、多传输协议、多序列化协议等各种复杂的功能，使得SOA架构下的分布式系统具备高可用的能力。 多语言支持CORBAR为了解决异构平台的RPC，使用了IDL（Interface Definition Language）来定义远程接口，并将其映射到特定的平台语言中。后来大部分的跨语言平台RPC基本都采用了此类方式，比如我们熟悉的Web Service（SOAP），近年开源的 Thrift等。他们大部分都通过IDL定义，并提供工具来映射生成不同语言平台的user-stub和server-stub，并通过框架库来提供RPCRuntime的支持。不过貌似每个不同的RPC框架都定义了各自不同的IDL格式，导致程序员的学习成本进一步上升，Web Service尝试建立业界标准，无赖标准规范复杂而效率偏低，否则Thrift等更高效的RPC框架就没必要出现了。IDL 是为了跨平台语言实现RPC不得已的选择，要解决更广泛的问题自然导致了更复杂的方案。而对于同一平台内的 RPC 而言显然没必要搞个中间语言出来，例如Java原生的RMI，这样对于java程序员而言显得更直接简单，降低使用的学习成本。 参考http://www.cnblogs.com/mindwind/p/5518145.htmlhttps://zh.wikipedia.org/wiki/%E9%9D%A2%E5%90%91%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%9E%B6%E6%9E%84http://www.baike.com/wiki/SOA%E6%9E%B6%E6%9E%84https://segmentfault.com/q/1010000003049016http://www.infoq.com/cn/articles/micro-soa-2?utm_source=infoq&amp;utm_campaign=user_page&amp;utm_medium=linkhttp://www.infoq.com/cn/articles/micro-soa-1?utm_source=infoq&amp;utm_campaign=user_page&amp;utm_medium=linkhttp://itindex.net/detail/51931-soa-api-%E5%88%86%E8%A3%82http://www.cnblogs.com/zhangz721/archive/2009/10/02/1577316.html 如若在茫茫宇宙中窥见了一丝真理，那该是何等之幸事。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>SOA</tag>
        <tag>RPC</tag>
        <tag>WebService</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet和JSP]]></title>
    <url>%2F2017%2F08%2F22%2Fjava%2FJSP%E5%92%8CServlet%2F</url>
    <content type="text"><![CDATA[在我们面试的时候一般会被问到，”Servlet和JSP有什么区别和联系？”。那么今天我们就来回答一下这个问题，顺便复习一下Servlet和JSP的一些相关知识。 JSP出现 JSP（全称JavaServer Pages）是由Sun Microsystems公司倡导和许多公司参与共同创建的一种使软件开发者可以响应客户端请求，而动态生成HTML、XML或其他格式文档的Web网页的技术标准。JSP技术是以Java语言作为脚本语言的，JSP网页为整个服务器端的Java库单元提供了一个接口来服务于HTTP的应用程序。从架构上说，JSP可以被看作是从Servlets高级提炼而作为JAVA Servlet 2.1 API的扩展而应用。Servlets和JSP最早都是由Sun Microsystems（太阳公司）开发的。 随着大量的B/S架构程序开发出来以后，人们发现Servlet类的编写是非常繁琐的，主要集中在几个问题上：首先有大量冗余代码，这些代码在每个servlet类中都是一模一样或者基本近似的，其次是开发Servlet的程序员很少有精通美工的，导致使用Servlet开发无法方便的做到各种页面效果和丰富多彩的风格，这个时候sun借鉴了微软的ASP方式，正式提出JSP（也就是Servlet 1.1），JSP推出后，JAVA程序员也能象ASP的程序员那样将服务端代码添加在已经由美工设计好的静态页面上，经过一个JSP容器对JSP文件进行自动解析并转换成Servlet类来交给WEB服务器运行。这么一来，极大的提高了工作效率。 工作方式当客户端浏览器向服务器请求一个 JSP 页面时，服务器收到该请求后，首先检查所请求的这个JSP 文件内容 ( 代码 ) 是否已经被更新，或者是否是 JSP 文件创建后的第一次被访问，如果是，那么，这个 JSP 文件就会在服务器端的 JSP 引擎作用下转化为一个 Servlet 类的 Java 源代码文件。紧接着，这个 Servlet 类会在 Java 编译器的作用下被编译成一个字节码文件，并装载到 jvm 解释执行。剩下的就等同于 Servlet 的处理过程了。如果被请求的 JSP 文件内容 ( 代码 ) 没有被修改，那么它的处理过程也等同于一个 Servlet 的处理过程。即直接由服务器检索出与之对应的Servlet 实例来处理。一种是预编译，也就是当Tomcat启动的时候，所有部署的应用中的jsp都会进行编译，另外一种是当第一次访问的时候对该jsp进行编译；无论是哪一种，JSPCompilationContext都是编译的上下文，JSPServletWrapper通过JSPCompilationContext进行加载jsp源文件，然后调用对应的Compiler进行编译为servlet的class，并通过JasperLoader进行加载。 Servlet定义Servlet（Server Applet），全称Java Servlet，未有中文译文。是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。Servlet运行于支持Java的应用服务器中。从实现上讲，Servlet可以响应任何类型的请求，但绝大多数情况下Servlet只用来扩展基于HTTP协议的Web服务器。最早支持Servlet标准的是JavaSoft的Java Web Server。此后，一些其它的基于Java的Web服务器开始支持标准的Servlet。 Servlet规范Servlet规范 Servlet容器Servlet容器是web server或application server的一部分，提供基于请求/响应发送模型的网络服务，解码基于MIME的请求，并且格式化基于MIME的响应。Servlet 容器也包含了管理Servlet生命周期。Servlet容器可以嵌入到宿主的web server中，或者通过Web Server的本地扩展API单独作为附加组件安装。Servelt容器也可能内嵌或安装到包含web功能的application server中。所有Servlet容器必须支持基于HTTP协议的请求/响应模型，比如像基于HTTPS（HTTP over SSL）协议的请求/应答模型可以选择性的支持。容器必须实现的HTTP协议版本包含HTTP/1.0 和 HTTP/1.1。因为容器或许支持RFC2616 (HTTP/1.1)描述的缓存机制，缓存机制可能在将客户端请求交给Servlet处理之前修改它们，也可能在将Servlet生成的响应发送给客户端之前修改它们，或者可能根据RFC2616规范直接对请求作出响应而不交给Servlet进行处理。Servlet容器应该使Servlet执行在一个安全限制的环境中。在Java平台标准版（J2SE, v.1.3 或更高） 或者 Java平台企业版(Java EE, v.1.3 或更高) 的环境下，这些限制应该被放置在Java平台定义的安全许可架构中。比如，高端的application server为了保证容器的其他组件不受到负面影响可能会限制Thread对象的创建。Java SE 6是构建Servlet容器最低的Java平台版本。 Servlet生命周期1、在servlet容器或web server启动时，对servlet进行实例化，此时调用servlet的构造方法；servlet实例化后，调用该servlet实例的init方法，对servlet进行一些初始化处理，处理完成后，将该servlet注入到servlet容器中;2、当client向web server或servlet容器请求servlet时，web server或servlet容器首先会根据请求的servlet名称去servlet容器中找对应的servlet，如果servlet不存在该名称对应的servlet，则向client响应请求不存在等信息，否则进行步骤3；3、如果请求的servlet存在于servlet容器，则调用servlet的service方法，生成动态资源，响应给client; （记住，整个过程该servlet只有一个实例，即单例）；4、当web server退出或servlet容器销毁时，调用servlet的destroy方法，最后唯一的sevlet实例将会被GC。在整个Servlet的生命周期过程中，创建Servlet实例、调用实例的init()和destroy()方法都只进行一次，当初始化完成后，Servlet容器会将该实例保存在内存中，通过调用它的service()方法，为接收到的请求服务。servlet只会实例化一次，servlet容器启动时或者第一次处理请求时之后所有请求都只共享这一个实例，每个请求对应一个线程去处理，线程池方式处理JSP/Servlet容器默认是采用单实例多线程(这是造成线程安全的主因)方式处理多个请求的。 线程安全问题由于servlet只会实例化一次，整个生命周期内所有的请求，都由这一个实例来完成，每个请求对应一个线程去处理，很容易造成线程安全性问题。如果service()方法没有访问Servlet的成员变量也没有访问全局的资源比如静态变量、文件、数据库连接等，而是只使用了当前线程自己的资源，比如非指向全局资源的临时变量、request和response对象等。该方法本身就是线程安全的，不必进行任何的同步控制。如果service()方法访问了Servlet的成员变量，但是对该变量的操作是只读操作，该方法本身就是线程安全的，不必进行任何的同步控制。如果service()方法访问了Servlet的成员变量，并且对该变量的操作既有读又有写，通常需要加上同步控制语句。如果service()方法访问了全局的静态变量，如果同一时刻系统中也可能有其它线程访问该静态变量，如果既有读也有写的操作，通常需要加上同步控制语句。如果service()方法访问了全局的资源，比如文件、数据库连接等，通常需要加上同步控制语句。 JSP本质上就是servletJava服务器页面（JSP）是HttpServlet的扩展。由于HttpServlet大多是用来响应HTTP请求，并返回Web页面（例如HTML、XML），所以不可避免地，在编写servlet时会涉及大量的HTML内容，这给servlet的书写效率和可读性带来很大障碍，JSP便是在这个基础上产生的。其功能是使用HTML的书写格式，在适当的地方加入Java代码片段，将程序员从复杂的HTML中解放出来，更专注于servlet本身的内容。JSP在首次被访问的时候被应用服务器转换为servlet，在以后的运行中，容器直接调用这个servlet，而不再访问JSP页面。所以说JSP本质上就是servlet,在执行的时候最终会被编译成servlet。JSP加入了各种Web标签，使其能更加方便的编写动态Web应用程序。JSP 由 HTML 代码和 JSP 标签构成，可以方便地编写动态网页,Servlet完全是JAVA程序代码构成擅长于流程控制和事务处理.因此在实际应用中采用 Servlet 来控制业务流程,而采用 JSP 来生成动态网页.Servlet和JSP两者分工协作，Servlet侧重于解决运算和业务逻辑问题，JSP则侧重于解决展示问题。 容器和serverweb server只要Web上的Server都叫Web Server，但是大家分工不同，解决的问题也不同，所以根据Web Server提供的功能，每个Web Server的名字也会不一样。按功能分类，Web Server可以分为：Http server和Application server。 Http serverHTTP Server本质上也是一种应用程序——它通常运行在服务器之上，绑定服务器的IP地址并监听某一个tcp端口来接收并处理HTTP请求，这样客户端（一般来说是IE, Firefox，Chrome这样的浏览器）就能够通过HTTP协议来获取服务器上的网页（HTML格式）、文档（PDF格式）、音频（MP4格式）、视频（MOV格式）等等资源。HTTP Server中经常使用的是Apache、Nginx两种，HTTP Server主要用来做静态内容服务、代理服务器、负载均衡等。直面外来请求转发给后面的应用服务（Tomcat，django什么的）。 Application ServerApplication Server 是一个应用执行的服务器。它首先需要支持开发语言的 Runtime（对于 Tomcat 来说，就是 Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。与HTTP Server相比，Application Server能够动态的生成资源并返回到客户端。 Application server可以作为servlet容器，tomcat、jeety等都是Application server都可以作为servlet容器。对于Tomcat来说，就是需要提供 JSP/Sevlet 运行需要的标准类库、Interface 等。为了方便，应用服务器往往也会集成 HTTP Server 的功能，但是不如专业的 HTTP Server 那么强大，所以Application Server往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端。 在实际运行的时候Java Servlet与Web服务器会融为一体，如同一个程序一样运行在同一个Java虚拟机（JVM）当中。与CGI不同的是，Servlet对每个请求都是单独启动一个线程，而不是进程。这种处理方式大幅度地降低了系统里的进程数量，提高了系统的并发处理能力。另外因为Java Servlet是运行在虚拟机之上的，也就解决了跨平台问题。如果没有Servlet的出现，也就没有互联网的今天。 参考https://my.oschina.net/xianggao/blog/670681http://www.hollischuang.com/archives/849http://developer.51cto.com/art/201012/237827.htmhttp://www.10tiao.com/html/308/201609/2650076215/1.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>servlet</tag>
        <tag>jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git多账号配置（Windows平台）]]></title>
    <url>%2F2017%2F08%2F21%2Fgit%E5%A4%9A%E8%B4%A6%E5%8F%B7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Git的配置相信大家都不陌生了，如果还不熟悉，不要着急，继续往下看就好了。今天主要看一下多账户的场景，顺便也复习一下Git的配置流程。 什么情况下需要多账户的配置呢？1.在公司一般大家都会配置公司的代码仓库的账户，用的账号一般是公司企业邮箱账号,比如zhangsan@XXX.com,一般的配置流程都是企业入职的时候给一个配置清单或者新手指导，员工自己按照指导去配置，无非也就是用git的SSH 命令生成密钥对，然后将公钥上传至管理平台，就可以很开心的写Bug了，哦 不对，写码。但是某一天有这样一个场景，有时候自己也会写点代码，这些代码一般我们托管在GitHub等平台上，这个时候就无法使用公司的账号了，需要再配置一个GitHub的账号，比如zhangsan@Gmail.com这样的账户名字。2.由于天朝独特的网络环境,你们懂得，有时候GitHub无法连接或者不稳定，这个时候需要有一个国内的代码托管平台，国内比如码云这样的平台也可以托管代码，速度比较稳定。这个时候就需要同时配置GitHub和码云两个账户。 具体配置第一种情况 公司账户和GitHub账户（不同邮箱） 1.如果原来配置过一次，在用户目录下会有一个.ssh目录，里面存放着你默认第一次生成的秘钥对，id_rsa和id_rsa.pub,在此目录打开Git bash 输入命令 ssh-keygen -C &quot;zhangsan@Gmail.com&quot; -t rsa 然后回车 这个时候需要注意，需要给生成的秘钥对命名，比如id_rsa_github，不然会以默认的名字id_rsa生成，从而覆盖掉原来生成的。然后回车两次，就可以成功生成秘钥。2.生成秘钥成功后，把生成公钥上传到GitHub的秘钥管理平台上，然后最重要的步骤来了。回到用户目录的.ssh目录，创建一个config文本文件，注意这个文件名字为config，没有后缀名，尝试过加上.config后缀，貌似不会被识别。这个配置文件就是告诉ssh多个账户下，每个账户对应的秘钥位置和Host位置。config配置文件1234567891011# github Host github.comHostName github.comUser zhangsanIdentityFile ~/.ssh/id_rsa_github# companyHost code.company.comHostName code.company.comUser zhangsanIdentityFile ~/.ssh/id_rsa 这样配置就结束了，打开git bash 输入命令测试一下ssh -T git@github.com成功的话会收到这样一段回复Hi zhangsan! You&#39;ve successfully authenticated, but GitHub does not provide shell access.不成功的话，检查下上面的配置，或者使用ssh -vT git@github.com 查看下详细的错误信息。3.有些网友的帖子会说如果配置了全局的Git用户名和邮箱，需要去掉，其实不去掉也是可以的。如果你先设置了公司的账户为全局配置，那么你克隆GitHub上的代码到本地后，只要在那个目录设置本地的用户名和邮箱，就可以了，因为本地的优先级要大于全局的设定，公司的代码目录则继续使用全局配置，一样的互不影响。 第二种情况 GitHub和码云两个账号 1.不同邮箱如果你同时拥有GitHub和码云两个账号，而又不是使用同一邮箱注册，其实也类似于上面这张情况，分别生成不同邮箱的秘钥，然后再config文件里配置相应的用户、秘钥位置和Host就可以了。2.相同邮箱如果是相同的邮箱，就不需要上面的配置，只要用这个邮箱生成一次秘钥，这个秘钥可以同时用在两个网站上，两个远程仓库都可以提交，因为SSH秘钥是用邮箱生成的，邮箱相同，则秘钥也相同，所以可以共用一个。 参考http://www.jianshu.com/p/89cb26e5c3e8https://gist.github.com/suziewong/4378434http://noahsnail.com/2016/08/31/2016-9-1-Git%E5%A4%9A%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AE/https://steflerjiang.github.io/2016/12/16/git%E5%A4%9A%E8%B4%A6%E5%8F%B7%E9%85%8D%E7%BD%AE/]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SonarQube 服务搭建与配置]]></title>
    <url>%2F2017%2F08%2F20%2Fsonar%E6%9C%AC%E5%9C%B0%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[SonarQube是神马 1.SonarQube（又叫Sonar）是对代码进行静态检测的开源平台,利用这个工具可以发现我们代码里各种隐藏的Bug和潜在的问 题，在团队协作的开发模式中可以更好的控制代码质量。 2.支持多种平台（Windows、Linux）和多种开发语言(java、C#、JavaScript、PHP等),并可以和Jekins、JIRA等多种外部工具和IntelliJ IDEA等开发工具无缝集成。 3.可视化界面，提供各种维度的质量查询和分析。 如何使用准备工作 下载软件SonarQube https://www.sonarqube.org/downloads/规则插件 checkstyle https://github.com/checkstyle/sonar-checkstylepmd https://github.com/SonarQubeCommunity/sonar-pmdfindbugs https://github.com/SonarQubeCommunity/sonar-findbugs汉化插件 sonar-l10n-zh-master https://github.com/SonarQubeCommunity/sonar-l10n-zh本地扫描插件 sonar-runner-dist-2.4 http://repo1.maven.org/maven2/org/codehaus/sonar/runner/sonar-runner-dist/2.4/以上插件均是源码 需要下载后自行编译 所需环境JDK1.7或以上MavenMysql 配置a.sonarqube\conf 配置sonar.properties内容 123sonar.jdbc.username=sonarsonar.jdbc.password=sonarsonar.jdbc.url=jdbc:mysql://127.0.0.1:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance b.mysql 配置 在mysql管理器中执行如下脚本创建数据库及mysql用户 12345CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci; CREATE USER 'sonar' IDENTIFIED BY 'sonar';GRANT ALL ON sonar.* TO 'sonar'@'%' IDENTIFIED BY 'sonar';GRANT ALL ON sonar.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar';FLUSH PRIVILEGES; mysql max_allowed_packet配置路径 C:\ProgramData\MySQL\MySQL Server 5.6\my.ini设置 max_allowed_packet=101943040 插件编译 安装分别编译下载的插件,去掉snapshort标记,放入插件目录下sonarqube-6.4\extensions\plugins 启动至此,启动mysql,启动sonarqube,本地访问 http://localhost:9000/可看到管理界面登录名\密码 admin\admin 扫描配置 maven扫描 配置maven配置文件添加节点 123456789101112131415161718&lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;&lt;![CDATA[jdbc:mysql://127.0.0.1:3306/sonar]]&gt; &lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.driver&gt;com.mysql.jdbc.Driver&lt;/sonar.jdbc.driver&gt; &lt;sonar.jdbc.username&gt;sonar&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;sonar&lt;/sonar.jdbc.password&gt;&lt;sonar.jdbc.maxWait&gt;50000&lt;/sonar.jdbc.maxWait&gt;&lt;sonar.jdbc.minEvictableIdleTimeMillis&gt;600000&lt;/sonar.jdbc.minEvictableIdleTimeMillis&gt; &lt;sonar.jdbc.timeBetweenEvictionRunsMillis&gt;30000&lt;/sonar.jdbc.timeBetweenEvictionRunsMillis&gt; &lt;sonar.host.url&gt;http://localhost:9000&lt;/sonar.host.url&gt; &lt;/properties&gt;&lt;/profile&gt; 执行maven命令mvn sonar:sonar 可扫描项目并上传质量报告 sonar-runner 扫描配置a.环境变量配置系统环境变量 12SONAR_RUNNER_HOME D:\Java\sonar-runner-2.4Path 追加 ;%SONAR_RUNNER_HOME%\bin; b.sonar-runner.properties配置文件 12345678910111213141516171819202122232425262728#Configure here general information about the environment, such as SonarQube DB details for example#No information about specific project should appear here #----- Default SonarQube serversonar.host.url=http://localhost:9000 #----- PostgreSQL#sonar.jdbc.url=jdbc:postgresql://localhost/sonar #----- MySQLsonar.jdbc.url=jdbc:mysql://127.0.0.1:3306/sonar?useUnicode=true&amp;amp;characterEncoding=utf8 #----- Oracle#sonar.jdbc.url=jdbc:oracle:thin:@localhost/XE #----- Microsoft SQLServer#sonar.jdbc.url=jdbc:jtds:sqlserver://localhost/sonar;SelectMethod=Cursor #----- Global database settingssonar.jdbc.username=sonarsonar.jdbc.password=sonar #----- Default source code encodingsonar.sourceEncoding=UTF-8 #----- Security (when 'sonar.forceAuthentication' is set to 'true')sonar.login=adminsonar.password=admin c、本地项目配置文件 项目根目录sonar-project.properties配置文件 123456789101112sonar.projectKey=projectKey sonar.projectName=projectNamesonar.projectVersion=1.0# Set modules IDssonar.modules=projectmodules# Modules inherit properties set at parent levelsonar.sources=srcsonar.sourceEncoding=UTF-8sonar.language=javasonar.java.binaries=target# By default, the base directory for a module is &lt;current_dir&gt;/&lt;module_ID&gt;. 至此 使用命令行进入到项目根目录输入命令 sonar-runner 可以完成项目的扫描和上传报告 参考https://zhuanlan.zhihu.com/p/22926742http://blog.csdn.net/xiajian2010/article/details/22983825http://www.cnblogs.com/parryyang/p/6270402.html]]></content>
      <categories>
        <category>代码质量</category>
      </categories>
      <tags>
        <tag>SonarQube</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub Pages博客搭建]]></title>
    <url>%2F2017%2F08%2F17%2Ffirstblog%2F</url>
    <content type="text"><![CDATA[闲扯一会生命不息，学习不止。最近读了不少书和博客,但是读下来发现了一些问题。比如，有些知识点看过很多次，每次看的时候都觉得似曾相识，却又记不起全貌。有些则是过目就忘，合上书本完全不记得书中所讲精要，甚是苦闷。这几日忽得夫人点拨，说是输出倒逼输入，意思就是充当别人的老师，然后逼自己学习更多的知识。这个道理大家自然都是懂得，只不过有时候做起来比较难以实践。一个是因为人都有惰性，好多事情都是停留在思想和嘴巴，付诸行动的少之又少。再者，也不太容易有机会充当别人的老师，而且本身我自己也不是那种好为人师的性格，倒不是清高装逼，也是怕误人子弟。不过我们这个行业比较特殊，可以有很好的方式去做输出倒逼输入的事情，比如写博客。其实很早就注册了博客园，但是到现在也只是酱油和灌水，没有发过帖子。现在决定写博客，把自己的输入真正变成自己的东西，一方面在写的过程中梳理一下知识，另一方面也记录下自己解决过的问题、踩过的坑。博客前期打算以Step By Step的教程为主，主要为了熟悉markdown语法和Hexo博客的使用，后面会慢慢转向原理解析类和日常踩坑记录类。往者不可谏,来者犹可追。 博客搭建GitHub Pages 设置 Github Pages 是 Github 公司提供的免费的静态网站托管服务，用起来方便而且功能强大，不仅没有空间限制，还可以绑定自己的域名。在 https://pages.github.com/ 首页上可以看到很多用 Github Pages 托管的网站，很漂亮。另外很多非常著名的公司和项目也都用这种方式来搭建网站，如微软和 twitter 的网站，还有 谷歌的 Material Design 图标 网站。本博客就是利用Github Pages托管所建。开始创建自己的网站： 创建一个新的仓库 yourname.github.io，yourname 就是你github的用户名，不可以是其他字符，不然访问不到。 只要把静态的网站文件上传到这个仓库，然后访问https://yourname.github.io，就可以看到自己的网站了。 安装Hexo Hexo出自台湾大学生tommy351之手，是一个基于Node.js的静态博客程序，其编译上百篇文字只需要几秒。hexo生成的静态网页可以直接放到GitHub Pages，BAE，SAE等平台上。 所需环境 Nodejs Git 1.首先安装好Nodejs和Git,Hexo安装过程中，有些文件是通过Git下载下来。安装cnpm 由于天朝网路环境问题，所以最好安装cnpm 淘宝的镜像，下载比较快npm install -g cnpm --registry=https://registry.npm.taobao.org全局安装hexocnpm install hexo-cli -g新建一个hexo/blog文件夹进入到你的hexo/blog目录打开git bashcnpm install hexo --save检查是否安装成功hexo -v初始化Hexohexo init这里会创建一些文件然后输入cnpm install这里要等一会，安装组件 2.然后就可以使用了常用命令hexo new &quot;Hello World&quot; 创建新页面hexo generate 重新生成所有页面hexo server 启动本地预览 预览地址 http://localhost:4000 会看到一个默认主题的hexo网站。 hexo new 命令会创建一个md格式的文件，就是我们写博客的文件，推荐使用markdownpad来写，支持各种markdown格式， 其实在使用过程中无需使用此命令创建，只要在blog下的\source\_posts文件夹下直接新建md格式的文件就可以了。Hexo在生成博客的时候回自动识别这个目录下写所有md文件。 3.发布到GitHub 找到blog目录下的_config.yml文件，加入以下节点123type: gitrepo: github: &lt;repository url&gt;,[branch] 执行命令hexo d 就可以完成发布，发布成功后，就可以在https://yourname.github.io看到自己更新的内容了，由于CDN缓存的缘故，有时候更新后要过一会才可以看到最新的内容。 参考 http://theme-next.iissnan.com/getting-started.html#theme-settings https://linghucong.js.org/2016/04/15/2016-04-15-hexo-github-pages-blog/ http://gitbeijing.com/pages.html http://www.jianshu.com/p/b8dd1e3e0255]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
